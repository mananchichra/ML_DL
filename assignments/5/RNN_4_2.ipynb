{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQKRnwgVJBWK",
        "outputId": "b7892208-24bc-49ed-b854-5211f7f5c15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.1461 | Val Loss: 0.9585 | Avg Correct Chars: 0.7209\n",
            "Prediction: nooooooiiiiii | Ground Truth: malcontentment________________\n",
            "Prediction: eeaiiii | Ground Truth: weeviled______________________\n",
            "Prediction: eeeeiiii | Ground Truth: enterozoa_____________________\n",
            "Prediction: eeee | Ground Truth: xylitol_______________________\n",
            "Prediction: eeeeiiii | Ground Truth: quindecad_____________________\n",
            "Epoch 2/10 | Train Loss: 0.9572 | Val Loss: 0.9515 | Avg Correct Chars: 0.7190\n",
            "Prediction: eeooooooooiie | Ground Truth: malcontentment________________\n",
            "Prediction: eeeeee | Ground Truth: weeviled______________________\n",
            "Prediction: eeeeeee | Ground Truth: enterozoa_____________________\n",
            "Prediction: eeeee | Ground Truth: xylitol_______________________\n",
            "Prediction: eeeoeeee | Ground Truth: quindecad_____________________\n",
            "Epoch 3/10 | Train Loss: 0.9379 | Val Loss: 0.9355 | Avg Correct Chars: 0.7222\n",
            "Prediction: oeerooooiiiiie | Ground Truth: malcontentment________________\n",
            "Prediction: eerriiie | Ground Truth: weeviled______________________\n",
            "Prediction: eerriiie | Ground Truth: enterozoa_____________________\n",
            "Prediction: eeriiie | Ground Truth: xylitol_______________________\n",
            "Prediction: eerreiiie | Ground Truth: quindecad_____________________\n",
            "Epoch 4/10 | Train Loss: 0.9299 | Val Loss: 0.9233 | Avg Correct Chars: 0.7283\n",
            "Prediction: penooooooaiiii | Ground Truth: malcontentment________________\n",
            "Prediction: uaraiiie | Ground Truth: weeviled______________________\n",
            "Prediction: uaraiiie | Ground Truth: enterozoa_____________________\n",
            "Prediction: kariie | Ground Truth: xylitol_______________________\n",
            "Prediction: oerraiiie | Ground Truth: quindecad_____________________\n",
            "Epoch 5/10 | Train Loss: 0.9218 | Val Loss: 1.0829 | Avg Correct Chars: 0.6910\n",
            "Prediction: nenooooooiiiiss | Ground Truth: malcontentment________________\n",
            "Prediction: iorooiiiie | Ground Truth: weeviled______________________\n",
            "Prediction: oonooiiiie | Ground Truth: enterozoa_____________________\n",
            "Prediction: iorooiiii | Ground Truth: xylitol_______________________\n",
            "Prediction: oonoooiiiie | Ground Truth: quindecad_____________________\n",
            "Epoch 6/10 | Train Loss: 0.9193 | Val Loss: 0.9247 | Avg Correct Chars: 0.7269\n",
            "Prediction: nenooooooiiiis | Ground Truth: malcontentment________________\n",
            "Prediction: ieriiie | Ground Truth: weeviled______________________\n",
            "Prediction: iereiii | Ground Truth: enterozoa_____________________\n",
            "Prediction: kaaiie | Ground Truth: xylitol_______________________\n",
            "Prediction: iereeiii | Ground Truth: quindecad_____________________\n",
            "Epoch 7/10 | Train Loss: 0.9229 | Val Loss: 0.9452 | Avg Correct Chars: 0.7218\n",
            "Prediction: neneeoooooiiies | Ground Truth: malcontentment________________\n",
            "Prediction: ueneiiie | Ground Truth: weeviled______________________\n",
            "Prediction: ueneeiiiee | Ground Truth: enterozoa_____________________\n",
            "Prediction: weiee | Ground Truth: xylitol_______________________\n",
            "Prediction: ueneeiiiee | Ground Truth: quindecad_____________________\n",
            "Epoch 8/10 | Train Loss: 0.9200 | Val Loss: 0.9501 | Avg Correct Chars: 0.7231\n",
            "Prediction: penoooooooaaiiis | Ground Truth: malcontentment________________\n",
            "Prediction: faaoiiie | Ground Truth: weeviled______________________\n",
            "Prediction: lenooiiee | Ground Truth: enterozoa_____________________\n",
            "Prediction: faliie | Ground Truth: xylitol_______________________\n",
            "Prediction: penoooiiie | Ground Truth: quindecad_____________________\n",
            "Epoch 9/10 | Train Loss: 0.9150 | Val Loss: 0.9172 | Avg Correct Chars: 0.7282\n",
            "Prediction: penooooooiiiii | Ground Truth: malcontentment________________\n",
            "Prediction: wereiie | Ground Truth: weeviled______________________\n",
            "Prediction: veroiiie | Ground Truth: enterozoa_____________________\n",
            "Prediction: jariie | Ground Truth: xylitol_______________________\n",
            "Prediction: uenooiiie | Ground Truth: quindecad_____________________\n",
            "Epoch 10/10 | Train Loss: 0.9118 | Val Loss: 0.9416 | Avg Correct Chars: 0.7211\n",
            "Prediction: penooooooaaaiis | Ground Truth: malcontentment________________\n",
            "Prediction: fartiiie | Ground Truth: weeviled______________________\n",
            "Prediction: iertoiiie | Ground Truth: enterozoa_____________________\n",
            "Prediction: fariie | Ground Truth: xylitol_______________________\n",
            "Prediction: uentoiiie | Ground Truth: quindecad_____________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download nltk words\n",
        "nltk.download(\"words\")\n",
        "\n",
        "# Constants\n",
        "IMG_WIDTH, IMG_HEIGHT = 256, 64\n",
        "FONT_SIZE = 32\n",
        "BLANK_CHAR = \"_\"\n",
        "MAX_WORD_LEN = 30\n",
        "DATASET_SIZE = 10000\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Helper function: Generate image with text\n",
        "def generate_image_with_text(text):\n",
        "    img = Image.new(\"L\", (IMG_WIDTH, IMG_HEIGHT), color=255)  # Plain white image\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", FONT_SIZE)\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", FONT_SIZE)\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    text_width = bbox[2] - bbox[0]\n",
        "    text_height = bbox[3] - bbox[1]\n",
        "    # text_width, text_height = draw.textsize(text, font=font)\n",
        "    x = (IMG_WIDTH - text_width) // 2\n",
        "    y = (IMG_HEIGHT - text_height) // 2\n",
        "    draw.text((x, y), text, font=font, fill=0)  # Black text\n",
        "    return np.array(img)\n",
        "\n",
        "# Task 1: Dataset\n",
        "def create_dataset():\n",
        "    all_words = [w for w in words.words() if len(w) <= MAX_WORD_LEN]\n",
        "    selected_words = random.sample(all_words, DATASET_SIZE)\n",
        "\n",
        "    images, labels = [], []\n",
        "    for word in selected_words:\n",
        "        word_padded = word.ljust(MAX_WORD_LEN, BLANK_CHAR)  # Pad with blank spaces\n",
        "        img = generate_image_with_text(word)\n",
        "        images.append(img)\n",
        "        labels.append(word_padded)\n",
        "\n",
        "    images = np.array(images).reshape(-1, 1, IMG_HEIGHT, IMG_WIDTH) / 255.0  # Normalize\n",
        "    return images, labels\n",
        "# Helper: Create a uniform distribution of words across alphabets\n",
        "def create_uniform_dataset():\n",
        "    # Group words by their starting letter\n",
        "    alphabet_groups = {chr(i): [] for i in range(97, 123)}  # Groups for 'a' to 'z'\n",
        "    for word in words.words():\n",
        "        if len(word) <= MAX_WORD_LEN and word[0].isalpha():  # Filter valid words\n",
        "            first_char = word[0].lower()\n",
        "            if first_char in alphabet_groups:\n",
        "                alphabet_groups[first_char].append(word)\n",
        "\n",
        "    # Sample words uniformly across all alphabets\n",
        "    words_per_group = DATASET_SIZE // len(alphabet_groups)  # Equal number of words per alphabet\n",
        "    selected_words = []\n",
        "    for group, word_list in alphabet_groups.items():\n",
        "        if len(word_list) >= words_per_group:\n",
        "            selected_words.extend(random.sample(word_list, words_per_group))\n",
        "        else:\n",
        "            selected_words.extend(word_list)  # Include all if not enough words\n",
        "\n",
        "    # Create dataset with images and padded labels\n",
        "    images, labels = [], []\n",
        "    for word in selected_words:\n",
        "        word_padded = word.ljust(MAX_WORD_LEN, BLANK_CHAR)  # Pad with blank spaces\n",
        "        img = generate_image_with_text(word)\n",
        "        images.append(img)\n",
        "        labels.append(word_padded)\n",
        "\n",
        "    images = np.array(images).reshape(-1, 1, IMG_HEIGHT, IMG_WIDTH) / 255.0  # Normalize\n",
        "    return images, labels\n",
        "\n",
        "# Generate the uniformly distributed dataset\n",
        "images, labels = create_uniform_dataset()\n",
        "\n",
        "# images, labels = create_dataset()\n",
        "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Helper: Create char-to-index and index-to-char mappings\n",
        "all_chars = list(set(\"\".join(labels)))  # Unique characters\n",
        "char_to_idx = {c: i for i, c in enumerate(all_chars)}\n",
        "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "num_classes = len(all_chars)\n",
        "\n",
        "# Dataset Class for PyTorch\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = torch.tensor(images, dtype=torch.float32)\n",
        "        self.labels = torch.tensor([[char_to_idx[c] for c in label] for label in labels], dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = OCRDataset(train_imgs, train_labels)\n",
        "val_dataset = OCRDataset(val_imgs, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Task 2: Model Architecture\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CRNN, self).__init__()\n",
        "        # Encoder (CNN)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2, 2),  # (32, 32, 128)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2, 2)  # (64, 16, 64)\n",
        "        )\n",
        "        self.fc = nn.Linear(64 * 16 * 64, 128)\n",
        "\n",
        "        # Decoder (RNN)\n",
        "        self.rnn = nn.LSTM(input_size=128, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.output_layer = nn.Linear(256, num_classes)  # 128*2 (bidirectional)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(batch_size, -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        x = x.unsqueeze(1).repeat(1, MAX_WORD_LEN, 1)  # Repeat for sequence length\n",
        "\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.output_layer(x)  # (batch_size, MAX_WORD_LEN, num_classes)\n",
        "        return x\n",
        "\n",
        "model = CRNN(num_classes).to(DEVICE)\n",
        "\n",
        "# Task 3: Training\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "\n",
        "            loss = 0\n",
        "            for t in range(MAX_WORD_LEN):\n",
        "                loss += criterion(outputs[:, t, :], labels[:, t])\n",
        "            loss /= MAX_WORD_LEN\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        val_loss, correct_chars, total_chars = 0, 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(imgs)\n",
        "\n",
        "                loss = 0\n",
        "                for t in range(MAX_WORD_LEN):\n",
        "                    loss += criterion(outputs[:, t, :], labels[:, t])\n",
        "                loss /= MAX_WORD_LEN\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=2)\n",
        "                correct_chars += (preds == labels).sum().item()\n",
        "                total_chars += labels.numel()\n",
        "\n",
        "        avg_correct_chars = correct_chars / total_chars\n",
        "\n",
        "        random_baseline_avg_correct = evaluate_random_baseline(val_loader, char_to_idx)\n",
        "\n",
        "    # Print Model Performance and Random Baseline Comparison\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Model Avg Correct Chars: {avg_correct_chars:.4f} | \"\n",
        "          f\"Random Baseline Avg Correct Chars: {random_baseline_avg_correct:.4f}\")\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss / len(train_loader):.4f} | \"\n",
        "              f\"Val Loss: {val_loss / len(val_loader):.4f} | Avg Correct Chars: {avg_correct_chars:.4f}\")\n",
        "\n",
        "        # Display a few predictions\n",
        "        sample_imgs, sample_labels = next(iter(val_loader))\n",
        "        sample_imgs, sample_labels = sample_imgs.to(DEVICE), sample_labels.to(DEVICE)\n",
        "        outputs = model(sample_imgs)\n",
        "        preds = torch.argmax(outputs, dim=2).cpu().numpy()\n",
        "        for i in range(5):\n",
        "            pred_text = \"\".join(idx_to_char[idx] for idx in preds[i] if idx != char_to_idx[BLANK_CHAR])\n",
        "            true_text = \"\".join(idx_to_char[idx] for idx in sample_labels[i].cpu().numpy())\n",
        "            print(f\"Prediction: {pred_text} | Ground Truth: {true_text}\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_random_baseline(val_loader, char_to_idx):\n",
        "    total_correct = 0\n",
        "    total_chars = 0\n",
        "\n",
        "    for imgs, labels in val_loader:\n",
        "        batch_size = labels.size(0)\n",
        "        random_preds = torch.randint(len(char_to_idx), (batch_size, MAX_WORD_LEN))  # Random predictions\n",
        "\n",
        "        correct_chars = (random_preds == labels).sum().item()\n",
        "        total_correct += correct_chars\n",
        "        total_chars += labels.numel()\n",
        "\n",
        "    avg_correct_chars = total_correct / total_chars\n",
        "    print(f\"Random Baseline | Avg Correct Chars: {avg_correct_chars:.4f}\")\n",
        "    return avg_correct_chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1J95chmYWzk",
        "outputId": "58ea5276-bb60-402d-f852-89d176f82bf2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimenting with Hyperparameters**"
      ],
      "metadata": {
        "id": "AUNOSBEoXMyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With Dropout and Normalisation\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, num_classes, hidden_size=128, num_layers=2, dropout_rate=0.3):\n",
        "        super(CRNN, self).__init__()\n",
        "        # Encoder (CNN)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2, 2),  # (32, 32, 128)\n",
        "            nn.Dropout2d(p=dropout_rate),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2, 2),  # (64, 16, 64)\n",
        "            nn.Dropout2d(p=dropout_rate),\n",
        "        )\n",
        "        self.fc = nn.Linear(64 * 16 * 64, 128)\n",
        "\n",
        "        # Decoder (RNN)\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=128,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout_rate,\n",
        "        )\n",
        "        self.output_layer = nn.Linear(2 * hidden_size, num_classes)  # 128*2 (bidirectional)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(batch_size, -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        x = x.unsqueeze(1).repeat(1, MAX_WORD_LEN, 1)  # Repeat for sequence length\n",
        "\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.output_layer(x)  # (batch_size, MAX_WORD_LEN, num_classes)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "KPfEvS-VXIFu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001, weight_decay=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "\n",
        "            loss = 0\n",
        "            for t in range(MAX_WORD_LEN):\n",
        "                loss += criterion(outputs[:, t, :], labels[:, t])\n",
        "            loss /= MAX_WORD_LEN\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        val_loss, correct_chars, total_chars = 0, 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(imgs)\n",
        "\n",
        "                loss = 0\n",
        "                for t in range(MAX_WORD_LEN):\n",
        "                    loss += criterion(outputs[:, t, :], labels[:, t])\n",
        "                loss /= MAX_WORD_LEN\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=2)\n",
        "                correct_chars += (preds == labels).sum().item()\n",
        "                total_chars += labels.numel()\n",
        "\n",
        "        avg_correct_chars = correct_chars / total_chars\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss / len(train_loader):.4f} | \"\n",
        "              f\"Val Loss: {val_loss / len(val_loader):.4f} | Avg Correct Chars: {avg_correct_chars:.4f}\")\n",
        "\n",
        "        # Display a few predictions\n",
        "        sample_imgs, sample_labels = next(iter(val_loader))\n",
        "        sample_imgs, sample_labels = sample_imgs.to(DEVICE), sample_labels.to(DEVICE)\n",
        "        outputs = model(sample_imgs)\n",
        "        preds = torch.argmax(outputs, dim=2).cpu().numpy()\n",
        "        for i in range(5):\n",
        "            pred_text = \"\".join(idx_to_char[idx] for idx in preds[i] if idx != char_to_idx[BLANK_CHAR])\n",
        "            true_text = \"\".join(idx_to_char[idx] for idx in sample_labels[i].cpu().numpy())\n",
        "            print(f\"Prediction: {pred_text} | Ground Truth: {true_text}\")\n"
      ],
      "metadata": {
        "id": "gGgWyYrNXex1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with Learning Rate:\n",
        "model = CRNN(num_classes).to(DEVICE)\n",
        "train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.01)  # Higher LR\n",
        "\n",
        "print('Now with a lower Learning Rate')\n",
        "train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.0001)  # Lower LR\n",
        "\n",
        "# Experiment with Dropout:\n",
        "model = CRNN(num_classes, hidden_size=128, num_layers=2, dropout_rate=0.5).to(DEVICE)  # Higher dropout\n",
        "print('Now with a Higher Dropout')\n",
        "train_model(model, train_loader, val_loader, num_epochs=10)\n",
        "\n",
        "# Experiment with LSTM Hidden Size:\n",
        "model = CRNN(num_classes, hidden_size=256, num_layers=2, dropout_rate=0.3).to(DEVICE)\n",
        "print('Now with changing LSTM Hidden Size')\n",
        "train_model(model, train_loader, val_loader, num_epochs=10)\n",
        "\n",
        "# Experiment with Weight Decay:\n",
        "print('Now with stronger Regularisation')\n",
        "train_model(model, train_loader, val_loader, num_epochs=10, weight_decay=1e-4)  # Stronger regularization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNl94tG2XkK4",
        "outputId": "f41bbba4-545c-4e76-ccaf-fd254fc5e79c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.1471 | Val Loss: 1.1058 | Avg Correct Chars: 0.7078\n",
            "Prediction: poooo | Ground Truth: myodynamic____________________\n",
            "Prediction: poooo | Ground Truth: wresting______________________\n",
            "Prediction: poooo | Ground Truth: emydosaurian__________________\n",
            "Prediction: poooo | Ground Truth: xarque________________________\n",
            "Prediction: poooo | Ground Truth: querimoniousness______________\n",
            "Epoch 2/10 | Train Loss: 1.0693 | Val Loss: 1.0452 | Avg Correct Chars: 0.7114\n",
            "Prediction: ueneoo | Ground Truth: myodynamic____________________\n",
            "Prediction: uentoo | Ground Truth: wresting______________________\n",
            "Prediction: ueneoo | Ground Truth: emydosaurian__________________\n",
            "Prediction: uetooo | Ground Truth: xarque________________________\n",
            "Prediction: ueneoo | Ground Truth: querimoniousness______________\n",
            "Epoch 3/10 | Train Loss: 1.0198 | Val Loss: 0.9490 | Avg Correct Chars: 0.7234\n",
            "Prediction: nanoooiiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: lantiii | Ground Truth: wresting______________________\n",
            "Prediction: nanooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalii | Ground Truth: xarque________________________\n",
            "Prediction: nenoooooiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 4/10 | Train Loss: 1.0196 | Val Loss: 1.0105 | Avg Correct Chars: 0.7168\n",
            "Prediction: qenoooo | Ground Truth: myodynamic____________________\n",
            "Prediction: qentooo | Ground Truth: wresting______________________\n",
            "Prediction: qeeooooe | Ground Truth: emydosaurian__________________\n",
            "Prediction: qonoo | Ground Truth: xarque________________________\n",
            "Prediction: ueneoooeee | Ground Truth: querimoniousness______________\n",
            "Epoch 5/10 | Train Loss: 1.0643 | Val Loss: 1.0668 | Avg Correct Chars: 0.7100\n",
            "Prediction: penooi | Ground Truth: myodynamic____________________\n",
            "Prediction: penooe | Ground Truth: wresting______________________\n",
            "Prediction: penooi | Ground Truth: emydosaurian__________________\n",
            "Prediction: penooe | Ground Truth: xarque________________________\n",
            "Prediction: penooe | Ground Truth: querimoniousness______________\n",
            "Epoch 6/10 | Train Loss: 1.0684 | Val Loss: 1.0529 | Avg Correct Chars: 0.7099\n",
            "Prediction: fonoo | Ground Truth: myodynamic____________________\n",
            "Prediction: fonoo | Ground Truth: wresting______________________\n",
            "Prediction: fonoo | Ground Truth: emydosaurian__________________\n",
            "Prediction: fonoo | Ground Truth: xarque________________________\n",
            "Prediction: fonooo | Ground Truth: querimoniousness______________\n",
            "Epoch 7/10 | Train Loss: 1.0642 | Val Loss: 1.0705 | Avg Correct Chars: 0.7106\n",
            "Prediction: zeree | Ground Truth: myodynamic____________________\n",
            "Prediction: zeree | Ground Truth: wresting______________________\n",
            "Prediction: zeree | Ground Truth: emydosaurian__________________\n",
            "Prediction: zeree | Ground Truth: xarque________________________\n",
            "Prediction: zeree | Ground Truth: querimoniousness______________\n",
            "Epoch 8/10 | Train Loss: 1.0504 | Val Loss: 0.9998 | Avg Correct Chars: 0.7167\n",
            "Prediction: ponoooii | Ground Truth: myodynamic____________________\n",
            "Prediction: wenii | Ground Truth: wresting______________________\n",
            "Prediction: oonooooii | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenii | Ground Truth: xarque________________________\n",
            "Prediction: ponooooii | Ground Truth: querimoniousness______________\n",
            "Epoch 9/10 | Train Loss: 1.0339 | Val Loss: 1.0101 | Avg Correct Chars: 0.7170\n",
            "Prediction: fonooaaa | Ground Truth: myodynamic____________________\n",
            "Prediction: fonoaaa | Ground Truth: wresting______________________\n",
            "Prediction: fonooaaa | Ground Truth: emydosaurian__________________\n",
            "Prediction: fonoia | Ground Truth: xarque________________________\n",
            "Prediction: fonooaaa | Ground Truth: querimoniousness______________\n",
            "Epoch 10/10 | Train Loss: 1.0286 | Val Loss: 0.9830 | Avg Correct Chars: 0.7195\n",
            "Prediction: banaooii | Ground Truth: myodynamic____________________\n",
            "Prediction: wanaoii | Ground Truth: wresting______________________\n",
            "Prediction: manaooiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: waaai | Ground Truth: xarque________________________\n",
            "Prediction: manooooii | Ground Truth: querimoniousness______________\n",
            "Now with a lower Learning Rate\n",
            "Epoch 1/10 | Train Loss: 1.0027 | Val Loss: 0.9762 | Avg Correct Chars: 0.7212\n",
            "Prediction: meneooii | Ground Truth: myodynamic____________________\n",
            "Prediction: weneii | Ground Truth: wresting______________________\n",
            "Prediction: meneoooie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wanei | Ground Truth: xarque________________________\n",
            "Prediction: meneoooie | Ground Truth: querimoniousness______________\n",
            "Epoch 2/10 | Train Loss: 0.9985 | Val Loss: 0.9713 | Avg Correct Chars: 0.7211\n",
            "Prediction: meneooii | Ground Truth: myodynamic____________________\n",
            "Prediction: weneiii | Ground Truth: wresting______________________\n",
            "Prediction: meneoooie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: meneoooie | Ground Truth: querimoniousness______________\n",
            "Epoch 3/10 | Train Loss: 0.9953 | Val Loss: 0.9685 | Avg Correct Chars: 0.7226\n",
            "Prediction: meneoooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: meneoooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: meneoooiie | Ground Truth: querimoniousness______________\n",
            "Epoch 4/10 | Train Loss: 0.9923 | Val Loss: 0.9668 | Avg Correct Chars: 0.7227\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penoooooie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: penoooooie | Ground Truth: querimoniousness______________\n",
            "Epoch 5/10 | Train Loss: 0.9895 | Val Loss: 0.9632 | Avg Correct Chars: 0.7229\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoiie | Ground Truth: wresting______________________\n",
            "Prediction: penooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: penoooooie | Ground Truth: querimoniousness______________\n",
            "Epoch 6/10 | Train Loss: 0.9881 | Val Loss: 0.9586 | Avg Correct Chars: 0.7225\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: penooooiie | Ground Truth: querimoniousness______________\n",
            "Epoch 7/10 | Train Loss: 0.9867 | Val Loss: 0.9574 | Avg Correct Chars: 0.7223\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: wenei | Ground Truth: xarque________________________\n",
            "Prediction: penooooiie | Ground Truth: querimoniousness______________\n",
            "Epoch 8/10 | Train Loss: 0.9865 | Val Loss: 0.9594 | Avg Correct Chars: 0.7234\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: feneii | Ground Truth: xarque________________________\n",
            "Prediction: penoooooii | Ground Truth: querimoniousness______________\n",
            "Epoch 9/10 | Train Loss: 0.9855 | Val Loss: 0.9531 | Avg Correct Chars: 0.7229\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penoooooie | Ground Truth: emydosaurian__________________\n",
            "Prediction: fenei | Ground Truth: xarque________________________\n",
            "Prediction: penoooooeee | Ground Truth: querimoniousness______________\n",
            "Epoch 10/10 | Train Loss: 0.9834 | Val Loss: 0.9502 | Avg Correct Chars: 0.7224\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: weneoii | Ground Truth: wresting______________________\n",
            "Prediction: penoooooie | Ground Truth: emydosaurian__________________\n",
            "Prediction: fenei | Ground Truth: xarque________________________\n",
            "Prediction: penoooooiie | Ground Truth: querimoniousness______________\n",
            "Now with a Higher Dropout\n",
            "Epoch 1/10 | Train Loss: 1.1617 | Val Loss: 0.9826 | Avg Correct Chars: 0.7189\n",
            "Prediction: uoooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: uaiiii | Ground Truth: wresting______________________\n",
            "Prediction: uoooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: eaiii | Ground Truth: xarque________________________\n",
            "Prediction: uooooooiiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 2/10 | Train Loss: 0.9674 | Val Loss: 0.9601 | Avg Correct Chars: 0.7208\n",
            "Prediction: eeoooooiee | Ground Truth: myodynamic____________________\n",
            "Prediction: eeeeeee | Ground Truth: wresting______________________\n",
            "Prediction: eeoooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: eeeeee | Ground Truth: xarque________________________\n",
            "Prediction: eooooooooaee | Ground Truth: querimoniousness______________\n",
            "Epoch 3/10 | Train Loss: 0.9520 | Val Loss: 0.9368 | Avg Correct Chars: 0.7252\n",
            "Prediction: oenooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: eeroiie | Ground Truth: wresting______________________\n",
            "Prediction: oeooooooiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: eerii | Ground Truth: xarque________________________\n",
            "Prediction: oooooooooiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 4/10 | Train Loss: 0.9451 | Val Loss: 0.9652 | Avg Correct Chars: 0.7221\n",
            "Prediction: eenooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: eeiiiii | Ground Truth: wresting______________________\n",
            "Prediction: oenooooiiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: aaiii | Ground Truth: xarque________________________\n",
            "Prediction: oenoooooiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 5/10 | Train Loss: 0.9365 | Val Loss: 0.9282 | Avg Correct Chars: 0.7257\n",
            "Prediction: uenoooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: fariiie | Ground Truth: wresting______________________\n",
            "Prediction: uenooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalii | Ground Truth: xarque________________________\n",
            "Prediction: uonooooooaiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 6/10 | Train Loss: 0.9375 | Val Loss: 0.9380 | Avg Correct Chars: 0.7256\n",
            "Prediction: nenoooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: jariie | Ground Truth: wresting______________________\n",
            "Prediction: menooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jarie | Ground Truth: xarque________________________\n",
            "Prediction: nenoooooiiiie | Ground Truth: querimoniousness______________\n",
            "Epoch 7/10 | Train Loss: 0.9300 | Val Loss: 0.9394 | Avg Correct Chars: 0.7252\n",
            "Prediction: neneeeeiii | Ground Truth: myodynamic____________________\n",
            "Prediction: faneiie | Ground Truth: wresting______________________\n",
            "Prediction: nenoooeaiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaaie | Ground Truth: xarque________________________\n",
            "Prediction: penooooooaiii | Ground Truth: querimoniousness______________\n",
            "Epoch 8/10 | Train Loss: 0.9239 | Val Loss: 0.9293 | Avg Correct Chars: 0.7266\n",
            "Prediction: nenoooiiie | Ground Truth: myodynamic____________________\n",
            "Prediction: feniiie | Ground Truth: wresting______________________\n",
            "Prediction: nenooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalie | Ground Truth: xarque________________________\n",
            "Prediction: nenoooooiiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 9/10 | Train Loss: 0.9219 | Val Loss: 0.9144 | Avg Correct Chars: 0.7285\n",
            "Prediction: perroeeeiie | Ground Truth: myodynamic____________________\n",
            "Prediction: rereeie | Ground Truth: wresting______________________\n",
            "Prediction: penrooooeiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jariee | Ground Truth: xarque________________________\n",
            "Prediction: penrooooooeiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 10/10 | Train Loss: 0.9195 | Val Loss: 0.9175 | Avg Correct Chars: 0.7275\n",
            "Prediction: penooiiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: jeriiii | Ground Truth: wresting______________________\n",
            "Prediction: penooooiiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaaii | Ground Truth: xarque________________________\n",
            "Prediction: penoooooiaiiii | Ground Truth: querimoniousness______________\n",
            "Now with changing LSTM Hidden Size\n",
            "Epoch 1/10 | Train Loss: 1.0888 | Val Loss: 0.9654 | Avg Correct Chars: 0.7198\n",
            "Prediction: eeeeeeiie | Ground Truth: myodynamic____________________\n",
            "Prediction: eeeeeie | Ground Truth: wresting______________________\n",
            "Prediction: eeeeeeeiiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: eeeee | Ground Truth: xarque________________________\n",
            "Prediction: eeeeooeeiie | Ground Truth: querimoniousness______________\n",
            "Epoch 2/10 | Train Loss: 0.9525 | Val Loss: 0.9303 | Avg Correct Chars: 0.7256\n",
            "Prediction: herooooiiie | Ground Truth: myodynamic____________________\n",
            "Prediction: uerriiie | Ground Truth: wresting______________________\n",
            "Prediction: oeoooooooiies | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaaiie | Ground Truth: xarque________________________\n",
            "Prediction: oeoooooooiies | Ground Truth: querimoniousness______________\n",
            "Epoch 3/10 | Train Loss: 0.9388 | Val Loss: 0.9505 | Avg Correct Chars: 0.7240\n",
            "Prediction: penooooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: wanaiie | Ground Truth: wresting______________________\n",
            "Prediction: penoooooaie | Ground Truth: emydosaurian__________________\n",
            "Prediction: walie | Ground Truth: xarque________________________\n",
            "Prediction: penoooooaii | Ground Truth: querimoniousness______________\n",
            "Epoch 4/10 | Train Loss: 0.9321 | Val Loss: 0.9203 | Avg Correct Chars: 0.7275\n",
            "Prediction: uenooooiii | Ground Truth: myodynamic____________________\n",
            "Prediction: fanoiii | Ground Truth: wresting______________________\n",
            "Prediction: uenoooooiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: fariie | Ground Truth: xarque________________________\n",
            "Prediction: uenooooooiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 5/10 | Train Loss: 0.9274 | Val Loss: 0.9171 | Avg Correct Chars: 0.7275\n",
            "Prediction: peneoeeeiie | Ground Truth: myodynamic____________________\n",
            "Prediction: deneeiee | Ground Truth: wresting______________________\n",
            "Prediction: peneooeeeiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalie | Ground Truth: xarque________________________\n",
            "Prediction: peneooooeeeiie | Ground Truth: querimoniousness______________\n",
            "Epoch 6/10 | Train Loss: 0.9269 | Val Loss: 0.9391 | Avg Correct Chars: 0.7254\n",
            "Prediction: nenoooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: raneiii | Ground Truth: wresting______________________\n",
            "Prediction: nenooooiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: rariie | Ground Truth: xarque________________________\n",
            "Prediction: nenoooooiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 7/10 | Train Loss: 0.9370 | Val Loss: 0.9283 | Avg Correct Chars: 0.7257\n",
            "Prediction: pentoooiie | Ground Truth: myodynamic____________________\n",
            "Prediction: fantiie | Ground Truth: wresting______________________\n",
            "Prediction: pentoooaii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaltee | Ground Truth: xarque________________________\n",
            "Prediction: penooooooaie | Ground Truth: querimoniousness______________\n",
            "Epoch 8/10 | Train Loss: 0.9358 | Val Loss: 0.9263 | Avg Correct Chars: 0.7264\n",
            "Prediction: uenooooiii | Ground Truth: myodynamic____________________\n",
            "Prediction: feneiie | Ground Truth: wresting______________________\n",
            "Prediction: penoooooiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalii | Ground Truth: xarque________________________\n",
            "Prediction: penoooooooii | Ground Truth: querimoniousness______________\n",
            "Epoch 9/10 | Train Loss: 0.9293 | Val Loss: 0.9314 | Avg Correct Chars: 0.7251\n",
            "Prediction: reneeeiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: yaniii | Ground Truth: wresting______________________\n",
            "Prediction: ieneooeaiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: yanii | Ground Truth: xarque________________________\n",
            "Prediction: neneoooeaiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 10/10 | Train Loss: 0.9287 | Val Loss: 0.9160 | Avg Correct Chars: 0.7278\n",
            "Prediction: penooooiii | Ground Truth: myodynamic____________________\n",
            "Prediction: waniiie | Ground Truth: wresting______________________\n",
            "Prediction: uenoooooaiis | Ground Truth: emydosaurian__________________\n",
            "Prediction: waniie | Ground Truth: xarque________________________\n",
            "Prediction: uenooooooonniis | Ground Truth: querimoniousness______________\n",
            "Now with stronger Regularisation\n",
            "Epoch 1/10 | Train Loss: 0.9360 | Val Loss: 0.9224 | Avg Correct Chars: 0.7265\n",
            "Prediction: qonooooiii | Ground Truth: myodynamic____________________\n",
            "Prediction: jeniiii | Ground Truth: wresting______________________\n",
            "Prediction: ponoooooiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaaii | Ground Truth: xarque________________________\n",
            "Prediction: penoooooiiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 2/10 | Train Loss: 0.9346 | Val Loss: 0.9420 | Avg Correct Chars: 0.7240\n",
            "Prediction: ieneeeeaii | Ground Truth: myodynamic____________________\n",
            "Prediction: lereeiie | Ground Truth: wresting______________________\n",
            "Prediction: ueneoeeeaiis | Ground Truth: emydosaurian__________________\n",
            "Prediction: yaliie | Ground Truth: xarque________________________\n",
            "Prediction: ueneoooeeaiiis | Ground Truth: querimoniousness______________\n",
            "Epoch 3/10 | Train Loss: 0.9330 | Val Loss: 0.9221 | Avg Correct Chars: 0.7274\n",
            "Prediction: penoooeiii | Ground Truth: myodynamic____________________\n",
            "Prediction: feroiiie | Ground Truth: wresting______________________\n",
            "Prediction: penooooeaais | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalii | Ground Truth: xarque________________________\n",
            "Prediction: penoooooeaaais | Ground Truth: querimoniousness______________\n",
            "Epoch 4/10 | Train Loss: 0.9390 | Val Loss: 0.9224 | Avg Correct Chars: 0.7271\n",
            "Prediction: uenoooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: waaiiii | Ground Truth: wresting______________________\n",
            "Prediction: uenoooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: walii | Ground Truth: xarque________________________\n",
            "Prediction: uenoooooaiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 5/10 | Train Loss: 0.9327 | Val Loss: 0.9198 | Avg Correct Chars: 0.7274\n",
            "Prediction: uenoooeiiie | Ground Truth: myodynamic____________________\n",
            "Prediction: wertiie | Ground Truth: wresting______________________\n",
            "Prediction: uenooooaiiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: jalie | Ground Truth: xarque________________________\n",
            "Prediction: uenoooooaiiie | Ground Truth: querimoniousness______________\n",
            "Epoch 6/10 | Train Loss: 0.9305 | Val Loss: 0.9254 | Avg Correct Chars: 0.7266\n",
            "Prediction: peneooeiiie | Ground Truth: myodynamic____________________\n",
            "Prediction: janiiie | Ground Truth: wresting______________________\n",
            "Prediction: peneoooeeiiie | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaiie | Ground Truth: xarque________________________\n",
            "Prediction: peneooooeeiiie | Ground Truth: querimoniousness______________\n",
            "Epoch 7/10 | Train Loss: 0.9311 | Val Loss: 0.9309 | Avg Correct Chars: 0.7254\n",
            "Prediction: ponooooaii | Ground Truth: myodynamic____________________\n",
            "Prediction: bariiie | Ground Truth: wresting______________________\n",
            "Prediction: ponoooooaii | Ground Truth: emydosaurian__________________\n",
            "Prediction: yalee | Ground Truth: xarque________________________\n",
            "Prediction: ponooooooaie | Ground Truth: querimoniousness______________\n",
            "Epoch 8/10 | Train Loss: 0.9248 | Val Loss: 0.9146 | Avg Correct Chars: 0.7272\n",
            "Prediction: peneoiiiiie | Ground Truth: myodynamic____________________\n",
            "Prediction: feniiiie | Ground Truth: wresting______________________\n",
            "Prediction: peneooiiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: faliie | Ground Truth: xarque________________________\n",
            "Prediction: peneoooooiiiiii | Ground Truth: querimoniousness______________\n",
            "Epoch 9/10 | Train Loss: 0.9251 | Val Loss: 0.9142 | Avg Correct Chars: 0.7276\n",
            "Prediction: uenoooeiii | Ground Truth: myodynamic____________________\n",
            "Prediction: qariiii | Ground Truth: wresting______________________\n",
            "Prediction: uenoooeeiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: jaiii | Ground Truth: xarque________________________\n",
            "Prediction: uenoooooeeiii | Ground Truth: querimoniousness______________\n",
            "Epoch 10/10 | Train Loss: 0.9257 | Val Loss: 0.9226 | Avg Correct Chars: 0.7263\n",
            "Prediction: uenooooiiii | Ground Truth: myodynamic____________________\n",
            "Prediction: garoiiie | Ground Truth: wresting______________________\n",
            "Prediction: uenoooooiiii | Ground Truth: emydosaurian__________________\n",
            "Prediction: karii | Ground Truth: xarque________________________\n",
            "Prediction: uenooooooiiii | Ground Truth: querimoniousness______________\n"
          ]
        }
      ]
    }
  ]
}