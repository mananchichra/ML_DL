Epoch 0, Loss: 0.7033767565560193
Epoch 1, Loss: 0.6834823797176426
Epoch 2, Loss: 0.6741909067324339
Epoch 3, Loss: 0.6682029487262675
Epoch 4, Loss: 0.6638598306369735
Epoch 5, Loss: 0.6606601574216018
Epoch 6, Loss: 0.6584120913079297
Epoch 7, Loss: 0.6566367065325154
Epoch 8, Loss: 0.6552480810152042
Epoch 9, Loss: 0.6542682586168129
Epoch 10, Loss: 0.6537652618284642
Epoch 11, Loss: 0.6538001090449644
Epoch 12, Loss: 0.6543999228070586
Epoch 13, Loss: 0.6554308604685954
Epoch 14, Loss: 0.6564314025447398
Epoch 15, Loss: 0.6569365367392537
Epoch 16, Loss: 0.6568109396612598
Epoch 17, Loss: 0.6562255016859687
Epoch 18, Loss: 0.6554143365590229
Epoch 19, Loss: 0.6545394846616762
Epoch 20, Loss: 0.6536842545554009
Epoch 21, Loss: 0.6528895508915997
Epoch 22, Loss: 0.6521655939269843
Epoch 23, Loss: 0.6515149748753615
Epoch 24, Loss: 0.650932746018627
Epoch 25, Loss: 0.6504158421570867
Epoch 26, Loss: 0.6499557207721357
Epoch 27, Loss: 0.6495457490863404
Epoch 28, Loss: 0.6491830160295706
Epoch 29, Loss: 0.6488613431329955
Epoch 30, Loss: 0.6485745274437018
Epoch 31, Loss: 0.6483202547312288
Epoch 32, Loss: 0.6480949508642649
Epoch 33, Loss: 0.6478946566588684
Epoch 34, Loss: 0.6477154521866754
Epoch 35, Loss: 0.6475566107564404
Epoch 36, Loss: 0.6474153645916954
Epoch 37, Loss: 0.6472896882248187
Epoch 38, Loss: 0.6471775529646709
Epoch 39, Loss: 0.6470784770974103
Epoch 40, Loss: 0.6469902477577483
Epoch 41, Loss: 0.6469116646860045
Epoch 42, Loss: 0.6468420954265446
Epoch 43, Loss: 0.6467796670912571
Epoch 44, Loss: 0.6467243093708442
Epoch 45, Loss: 0.6466744216132735
Epoch 46, Loss: 0.6466307357075081
Epoch 47, Loss: 0.6465918120791069
Epoch 48, Loss: 0.646556827245621
Epoch 49, Loss: 0.6465259699593782
Epoch 50, Loss: 0.6464984420316271
Epoch 51, Loss: 0.6464740693549207
Epoch 52, Loss: 0.646452091867691
Epoch 53, Loss: 0.6464326958411419
Epoch 54, Loss: 0.646415507088642
Epoch 55, Loss: 0.6464003866748073
Epoch 56, Loss: 0.6463863651472502
Epoch 57, Loss: 0.6463737797715244
Epoch 58, Loss: 0.646362956732726
Epoch 59, Loss: 0.6463531295081338
Epoch 60, Loss: 0.6463443537220195
Epoch 61, Loss: 0.6463367532463544
Epoch 62, Loss: 0.6463301226711289
Epoch 63, Loss: 0.6463239446188542
Epoch 64, Loss: 0.6463186102257447
Epoch 65, Loss: 0.6463137757479952
Epoch 66, Loss: 0.6463092581011852
Epoch 67, Loss: 0.6463053585802078
Epoch 68, Loss: 0.6463017901137375
Epoch 69, Loss: 0.6462987009513157
Epoch 70, Loss: 0.6462958891773046
Epoch 71, Loss: 0.6462933454059625
Epoch 72, Loss: 0.6462910789354359
Epoch 73, Loss: 0.6462892012046529
Epoch 74, Loss: 0.6462873980901946
Epoch 75, Loss: 0.646285774001015
Epoch 76, Loss: 0.6462842280667911
Epoch 77, Loss: 0.6462828272874833
Epoch 78, Loss: 0.6462816503936346
Epoch 79, Loss: 0.6462805403545968
Epoch 80, Loss: 0.6462795756566941
Epoch 81, Loss: 0.646278690606827
Epoch 82, Loss: 0.6462778480502778
Epoch 83, Loss: 0.6462770214769469
Epoch 84, Loss: 0.6462763384608715
Epoch 85, Loss: 0.6462756769119156
Epoch 86, Loss: 0.6462751168539793
Epoch 87, Loss: 0.6462746273132817
Epoch 88, Loss: 0.6462741900173549
Epoch 89, Loss: 0.6462737603248907
Epoch 90, Loss: 0.6462734438985178
Epoch 91, Loss: 0.6462731647910885
Epoch 92, Loss: 0.646272929357875
Epoch 93, Loss: 0.6462727699841855
Epoch 94, Loss: 0.6462727936278111
Epoch 95, Loss: 0.6462730079483788
Epoch 96, Loss: 0.6462734811298373
Epoch 97, Loss: 0.6462743704759076
Epoch 98, Loss: 0.6462754896674754
Epoch 99, Loss: 0.646277221577964
/home/mananchichra/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
